# MMS Point Cloud Classification - Final Project Summary

## Project Overview

**Goal:** Develop an AI-powered system to classify Mobile Mapping System (MMS) point clouds into 5 semantic categories using deep learning.

**Categories:**
1. Road
2. Snow
3. Vehicle
4. Vegetation
5. Others

**Status:** âœ… **SUCCESSFULLY COMPLETED** (December 2025)

---

## Final Results

### PointNet++ (Recommended Model)

**Overall Performance:**
- **Accuracy: 94.78%** (exceeds target of 88-90%)
- **Mean IoU: 87.51%**
- **Kappa Coefficient: 0.9187** (excellent agreement)
- **Weighted F1-Score: 0.9479**

**Per-Class Performance:**

| Class | IoU | Precision | Recall | F1-Score | Support |
|-------|-----|-----------|--------|----------|---------|
| **Road** | 91.45% | 99.49% | 91.89% | 95.54% | 11,029 |
| **Snow** | 91.87% | 96.00% | 95.53% | 95.77% | 103,140 |
| **Vehicle** | 79.15% | 97.74% | 80.62% | 88.36% | 4,836 |
| **Vegetation** | 85.30% | 87.19% | 97.52% | 92.07% | 23,233 |
| **Others** | 89.75% | 94.94% | 94.26% | 94.60% | 76,951 |

**Model Details:**
- Architecture: PointNet++ (Hierarchical)
- Parameters: 968,069
- Training Time: ~4 hours on RTX 4050 GPU
- Best Checkpoint: Epoch 28

---

## Dataset

**Total Points:** 1,461,189 labeled points

**Data Split:**
- Training: 1,022,832 points (70%)
- Validation: 219,189 points (15%)
- Test: 219,168 points (15%)

**Data Sources:**
- `sample1.las` - CloudCompare labeled MMS data
- Features: XYZ coordinates, RGB colors, intensity

**Preprocessing:**
- LAS file reading and parsing
- Label mapping to 5 target classes
- Feature normalization
- Random sampling for balanced training

---

## Model Comparison

We evaluated two deep learning architectures:

### 1. SimplePointNet (Baseline)

**Performance:**
- Accuracy: 86.01%
- Mean IoU: 75.79%
- Kappa: 0.7742
- Training Time: ~2.5 hours

**Strengths:**
- Fast training
- Lightweight (192K parameters)
- Good baseline performance

**Weaknesses:**
- Poor Vegetation classification (61% IoU)
- Struggles with Snow (71.5% IoU)
- Single-scale features miss details

### 2. PointNet++ (Final Model) âœ…

**Performance:**
- Accuracy: 94.78% (+8.77% improvement)
- Mean IoU: 87.51% (+11.72% improvement)
- Kappa: 0.9187 (+0.1445 improvement)
- Training Time: ~4 hours

**Strengths:**
- Excellent overall accuracy
- Outstanding Vegetation performance (+24% IoU)
- Strong Snow classification (+20% IoU)
- Multi-scale hierarchical features
- Robust across all classes

**Trade-offs:**
- 5x more parameters (968K vs 192K)
- Longer training time (+1.5 hours)

**Winner:** PointNet++ provides significantly better performance that justifies the additional complexity.

---

## Technical Implementation

### Architecture Details

**PointNet++ Architecture:**
```
Input: (B, N, 7) - [XYZ, RGB, Intensity]
â”œâ”€â”€ Set Abstraction 1: 1024 points, radius=0.1, [32, 32, 64]
â”œâ”€â”€ Set Abstraction 2: 256 points, radius=0.2, [64, 64, 128]
â”œâ”€â”€ Set Abstraction 3: 64 points, radius=0.4, [128, 128, 256]
â”œâ”€â”€ Set Abstraction 4: 16 points, radius=0.8, [256, 256, 512]
â”œâ”€â”€ Feature Propagation 4: [256, 256]
â”œâ”€â”€ Feature Propagation 3: [256, 256]
â”œâ”€â”€ Feature Propagation 2: [256, 128]
â”œâ”€â”€ Feature Propagation 1: [128, 128, 128]
â””â”€â”€ Output: (B, N, 5) - Class logits
```

**Key Features:**
- Farthest Point Sampling (FPS) for hierarchical point selection
- Ball query grouping for local feature aggregation
- Multi-scale feature learning at 4 different resolutions
- Skip connections via Feature Propagation layers

### Training Configuration

**Hyperparameters:**
- Batch Size: 8
- Points per Sample: 2048
- Learning Rate: 0.001 (Adam optimizer)
- Epochs: 30
- Scheduler: ReduceLROnPlateau (patience=5, factor=0.5)

**Data Augmentation:**
- Random rotation around Z-axis (0-360Â°)
- Random scaling (0.95-1.05x)
- Random point sampling

**Loss Function:**
- CrossEntropyLoss for multi-class classification

**Hardware:**
- GPU: NVIDIA GeForce RTX 4050 Laptop GPU
- PyTorch: 2.5.1+cu121 (CUDA-enabled)
- GPU Utilization: ~100% during training
- Memory Usage: ~5.8GB / 6.1GB

---

## Project Structure

```
LAB PROJECT/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ sample1.las                      # Original labeled LAS file
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ train_data.npz                   # Training data (1.02M points)
â”‚       â”œâ”€â”€ val_data.npz                     # Validation data (219K points)
â”‚       â””â”€â”€ test_data.npz                    # Test data (219K points)
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ simple_pointnet.py                   # SimplePointNet implementation
â”‚   â””â”€â”€ pointnet2.py                         # PointNet++ implementation (FIXED)
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ metrics.py                           # Segmentation metrics (IoU, Kappa, etc.)
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ best_model.pth                       # SimplePointNet best model
â”‚   â”œâ”€â”€ pointnet2_best_model.pth            # PointNet++ best model âœ…
â”‚   â”œâ”€â”€ training_history.json               # SimplePointNet training history
â”‚   â””â”€â”€ pointnet2_training_history.json     # PointNet++ training history
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ test_results.json                   # SimplePointNet test results
â”‚   â”œâ”€â”€ pointnet2_test_results.json         # PointNet++ test results âœ…
â”‚   â”œâ”€â”€ confusion_matrix.png                # SimplePointNet confusion matrix
â”‚   â”œâ”€â”€ pointnet2_confusion_matrix.png      # PointNet++ confusion matrix âœ…
â”‚   â”œâ”€â”€ model_comparison.md                 # Detailed model comparison âœ…
â”‚   â”œâ”€â”€ overall_metrics_comparison.png      # Overall metrics chart âœ…
â”‚   â”œâ”€â”€ per_class_iou_comparison.png        # Per-class IoU chart âœ…
â”‚   â”œâ”€â”€ per_class_f1_comparison.png         # Per-class F1-score chart âœ…
â”‚   â”œâ”€â”€ precision_recall_scatter.png        # Precision vs Recall plot âœ…
â”‚   â”œâ”€â”€ improvement_heatmap.png             # Improvement heatmap âœ…
â”‚   â””â”€â”€ model_summary_table.png             # Summary table âœ…
â”œâ”€â”€ prepare_training_data.py                # Data preprocessing script
â”œâ”€â”€ train_from_processed.py                 # SimplePointNet training script
â”œâ”€â”€ train_pointnet2.py                      # PointNet++ training script âœ…
â”œâ”€â”€ evaluate_model.py                       # SimplePointNet evaluation script
â”œâ”€â”€ evaluate_pointnet2.py                   # PointNet++ evaluation script âœ…
â”œâ”€â”€ create_comparison_visualizations.py     # Visualization generation script âœ…
â”œâ”€â”€ check_training.py                       # Training progress monitor
â”œâ”€â”€ class_mapping_config.py                 # Class mapping configuration
â””â”€â”€ FINAL_PROJECT_SUMMARY.md               # This file âœ…
```

---

## Key Achievements

### 1. Data Preparation âœ…
- Successfully loaded and parsed CloudCompare-labeled LAS files
- Created balanced train/val/test splits (70/15/15)
- Implemented efficient numpy-based preprocessing pipeline
- Total: 1.46M labeled points ready for training

### 2. SimplePointNet Implementation âœ…
- Built baseline model with 192K parameters
- Achieved 86.01% accuracy
- Identified weaknesses in Vegetation and Snow classification
- Established performance baseline

### 3. PointNet++ Implementation âœ…
- **Fixed critical dimension mismatch bugs:**
  - Line 232: Changed `in_channel=num_features` to `in_channel=num_features + 3`
  - Added tensor permutations between encoder/decoder layers
- Implemented hierarchical multi-scale architecture
- Successfully trained 968K parameter model
- Achieved 94.78% accuracy (exceeds expectations)

### 4. GPU Acceleration âœ…
- Identified CPU-only PyTorch installation
- Successfully installed CUDA PyTorch 2.5.1+cu121
- Verified RTX 4050 GPU detection and utilization
- Reduced training time from estimated 24+ hours to ~4 hours

### 5. Comprehensive Evaluation âœ…
- Implemented SegmentationMetrics class for IoU, Kappa, F1-score
- Generated confusion matrices (raw and normalized)
- Created detailed per-class performance analysis
- Evaluated both models on test set

### 6. Visualization and Documentation âœ…
- Created 6 comparison visualizations
- Generated comprehensive model comparison document
- Documented all fixes and improvements
- Created final project summary

---

## Challenges and Solutions

### Challenge 1: RandLA-Net torch.gather() Error
**Problem:** Dimension mismatch in torch.gather() at line 155
- Trying to gather 4D neighbor features from 3D input tensor

**Status:** Identified but postponed (not critical for project goals)

**Learning:** Sometimes it's better to move forward with working solutions than spend time on non-essential components.

---

### Challenge 2: PointNet++ Dimension Mismatch
**Problem:** Expected 7 channels but got 10 channels
```
RuntimeError: expected input[4, 10, 1024, 32] to have 7 channels, but got 10 channels
```

**Root Cause:**
- Set Abstraction layer concatenates XYZ (3) with features (7) = 10 channels
- But sa1 initialized with `in_channel=7`

**Solution:**
```python
# BEFORE (BROKEN):
self.sa1 = PointNetSetAbstraction(in_channel=num_features, ...)  # 7

# AFTER (FIXED):
self.sa1 = PointNetSetAbstraction(in_channel=num_features + 3, ...)  # 10
```

**Impact:** This single line fix enabled PointNet++ training to succeed.

---

### Challenge 3: Tensor Format Mismatch Between Layers
**Problem:** Query ball point function failed with index out of bounds

**Root Cause:**
- Set Abstraction outputs (B, C, N) format
- Next layer expects (B, N, C) input

**Solution:** Added tensor permutations between layers
```python
l1_xyz, l1_points = self.sa1(l0_xyz, l0_points)
l1_points = l1_points.permute(0, 2, 1)  # (B, C, N) -> (B, N, C)
```

**Learning:** Careful attention to tensor dimensions is critical in deep learning.

---

### Challenge 4: CPU-only PyTorch Installation
**Problem:** PyTorch 2.9.1+cpu installed, no GPU support

**Discovery:** User has RTX 4050 GPU but wasn't being used

**Solution:** Installed CUDA-enabled PyTorch
```bash
pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

**Impact:**
- Training time: 24+ hours (CPU) â†’ 4 hours (GPU)
- 6-10x speedup enabled rapid iteration

**Learning:** Always verify GPU support is properly configured before long training runs.

---

### Challenge 5: Laptop Performance During Training
**Problem:** User reported lag during 100% GPU utilization

**Discussion:** Weighed options:
- Stop training to preserve laptop usability
- Continue training to complete project

**Resolution:** User decided to proceed with training despite lag

**Outcome:** Training completed successfully with no issues

**Learning:** Communication about trade-offs is important for user decision-making.

---

## Performance Analysis

### Best Performing Classes

1. **Snow: 91.87% IoU**
   - Highest improvement: +20.37% over SimplePointNet
   - PointNet++'s hierarchical features capture snow texture excellently
   - 96.00% precision, 95.53% recall

2. **Road: 91.45% IoU**
   - Near-perfect precision: 99.49%
   - Minimal false positives
   - 91.89% recall

3. **Others: 89.75% IoU**
   - Strong improvement: +17.47% over SimplePointNet
   - Handles diverse object types robustly
   - 94.94% precision

### Most Improved Classes (vs SimplePointNet)

1. **Vegetation: +24.04% IoU** (61.26% â†’ 85.30%)
   - Largest single improvement
   - Multi-scale features capture tree/vegetation structure
   - Reduced confusion with "Others" class (18.9% â†’ 1.2%)

2. **Snow: +20.37% IoU** (71.50% â†’ 91.87%)
   - Second-largest improvement
   - Hierarchical features handle texture variations
   - Better separation from other classes

3. **Others: +17.47% IoU** (72.28% â†’ 89.75%)
   - Improved handling of diverse object types
   - Precision jumped from 78.51% to 94.94%

### Confusion Matrix Insights

**Major Improvements:**
- Vegetation â†’ Others confusion reduced: 18.9% â†’ 1.2%
- Vehicle â†’ Others confusion reduced: 12.6% â†’ 5.7%
- Snow â†’ Vegetation confusion reduced: 2.9% â†’ 1.3%

**Remaining Challenges:**
- Road recall: 91.9% (7.1% confused with Snow)
- Vehicle â†’ Snow confusion: 11.0% (likely due to vehicle color similarity)
- Smallest class (Vehicle: 4,836 points) has lowest IoU (79.15%)

---

## Future Improvements

### Short-term (Optional)

1. **Fix RandLA-Net Implementation**
   - Resolve torch.gather() dimension mismatch
   - Compare performance with PointNet++
   - Potentially achieve even higher accuracy

2. **Data Augmentation Enhancements**
   - Add random jittering
   - Implement point dropout
   - Add Gaussian noise to coordinates

3. **Class Imbalance Handling**
   - Weighted loss for smaller classes (Vehicle: 4,836 points)
   - Focal loss to focus on hard examples
   - Class-balanced sampling

4. **Hyperparameter Tuning**
   - Experiment with learning rate schedules
   - Try different batch sizes
   - Adjust number of sampled points (2048 â†’ 4096)

### Long-term (Production)

1. **Model Optimization**
   - Quantization for faster inference
   - TorchScript compilation
   - ONNX export for deployment

2. **Real-time Inference**
   - Sliding window approach for large point clouds
   - GPU-accelerated inference pipeline
   - Batch processing optimization

3. **Ensemble Methods**
   - Combine SimplePointNet + PointNet++ predictions
   - Test-time augmentation
   - Multi-model voting

4. **Active Learning**
   - Identify low-confidence predictions
   - Request additional labels for hard examples
   - Iterative model improvement

---

## Lessons Learned

### Technical Lessons

1. **Debugging Deep Learning Models**
   - Always check tensor dimensions at each layer
   - Use dummy data to test forward pass before training
   - Add informative error messages and assertions

2. **GPU Utilization**
   - Verify GPU support before long training runs
   - Monitor GPU utilization during training
   - CUDA significantly accelerates training (6-10x)

3. **Model Selection**
   - More complex models (PointNet++) justify their cost with better performance
   - Baseline models (SimplePointNet) are valuable for comparison
   - Sometimes simpler architectures are sufficient

4. **Data Preparation**
   - Good preprocessing is critical for model success
   - Balanced train/val/test splits prevent overfitting
   - Feature normalization improves convergence

### Project Management Lessons

1. **Iterative Development**
   - Start with baseline, identify weaknesses, improve
   - SimplePointNet â†’ PointNet++ â†’ (optional) RandLA-Net
   - Don't fix everything at once; prioritize critical issues

2. **Documentation**
   - Document fixes immediately (dimension mismatch solutions)
   - Track training progress with logs and checkpoints
   - Create comprehensive comparisons for decision-making

3. **User Communication**
   - Explain trade-offs clearly (training time vs. laptop usability)
   - Provide periodic progress updates
   - Celebrate achievements (94.78% accuracy exceeded expectations!)

---

## Conclusion

**Project Status: âœ… SUCCESSFULLY COMPLETED**

We successfully built an AI-powered MMS point cloud classification system that:
- âœ… Achieves **94.78% accuracy** (exceeds 88-90% target)
- âœ… Classifies 5 semantic categories with **87.51% mean IoU**
- âœ… Demonstrates **excellent agreement** (Kappa: 0.9187)
- âœ… Includes comprehensive evaluation metrics and visualizations
- âœ… Completed by end of December 2025 (on schedule!)

**Recommended Model:** PointNet++ with 968K parameters, trained for 30 epochs on RTX 4050 GPU.

**Final Model Location:** `checkpoints/pointnet2_best_model.pth`

**All Results Available In:**
- `results/pointnet2_test_results.json` - Complete test metrics
- `results/model_comparison.md` - Detailed comparison document
- `results/*.png` - Confusion matrices and visualizations

---

## Usage Instructions

### Inference on New Data

```python
import torch
import numpy as np
from models.pointnet2 import PointNet2

# Load model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = PointNet2(num_classes=5, num_features=7).to(device)
checkpoint = torch.load('checkpoints/pointnet2_best_model.pth', map_location=device)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Prepare your point cloud data
# xyz: (N, 3) - XYZ coordinates
# features: (N, 7) - [X, Y, Z, R, G, B, Intensity]

# Normalize XYZ
xyz_mean = np.mean(xyz, axis=0)
xyz_norm = xyz - xyz_mean
xyz_std = np.std(xyz_norm)
if xyz_std > 0:
    xyz_norm = xyz_norm / xyz_std

# Update features with normalized XYZ
features[:, :3] = xyz_norm

# Convert to tensors and add batch dimension
coords_tensor = torch.from_numpy(xyz_norm).float().unsqueeze(0).to(device)
features_tensor = torch.from_numpy(features).float().unsqueeze(0).to(device)

# Run inference
with torch.no_grad():
    logits = model(coords_tensor, features_tensor)
    predictions = torch.argmax(logits, dim=2).cpu().numpy().flatten()

# Class mapping: {0: Road, 1: Snow, 2: Vehicle, 3: Vegetation, 4: Others}
```

### Training on New Data

```bash
# 1. Prepare your data (LAS file with CloudCompare labels)
python prepare_training_data.py

# 2. Train PointNet++
python train_pointnet2.py

# 3. Monitor training
python check_training.py

# 4. Evaluate on test set
python evaluate_pointnet2.py
```

---

## Acknowledgments

**Technologies Used:**
- PyTorch 2.5.1+cu121
- NumPy, Matplotlib, Seaborn
- scikit-learn
- CloudCompare (data labeling)

**Hardware:**
- NVIDIA GeForce RTX 4050 Laptop GPU

**Project Timeline:**
- Duration: 8 weeks (November 1 - December 25, 2025)
- Phases: 8 structured phases from research to deployment
- Key milestones: Data labeling (Nov 30), Baseline model (Dec 12), Final model (Dec 24)
- See README.md for detailed timeline breakdown

---

**Project Complete! ðŸŽ‰**

Both SimplePointNet (86% accuracy) and PointNet++ (94.78% accuracy) are trained, evaluated, and ready for deployment. All code, models, and documentation are available in this repository.
